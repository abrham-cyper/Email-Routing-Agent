{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Agent 1: GPT-2 Prompting (Zero-shot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Project 2025: LLM Email Routing Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AutoTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# --- Agent 1: GPT-2 Prompting (Zero-shot) ---\u001b[39;00m\n\u001b[1;32m      3\u001b[0m model_name_gpt2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m tokenizer_gpt2 \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name_gpt2)\n\u001b[1;32m      5\u001b[0m model_gpt2 \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name_gpt2)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokenizer_gpt2\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AutoTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Agent 1: GPT-2 Prompting (Zero-shot) ---\n",
    "\n",
    "model_name_gpt2 = \"gpt2\"\n",
    "tokenizer_gpt2 = AutoTokenizer.from_pretrained(model_name_gpt2)\n",
    "model_gpt2 = AutoModelForCausalLM.from_pretrained(model_name_gpt2).to(device)\n",
    "\n",
    "if tokenizer_gpt2.pad_token is None:\n",
    "    tokenizer_gpt2.pad_token = tokenizer_gpt2.eos_token\n",
    "    model_gpt2.config.pad_token_id = model_gpt2.config.eos_token_id\n",
    "\n",
    "def generate_prompt_zeroshot(text):\n",
    "    return f\"Classify the email into one of the following departments: Technical Support, Customer Service, Billing and Payments, Sales and Pre-Sales, General Inquiry.\\n\\nEmail: {text}\\n\\nDepartment:\"\n",
    "\n",
    "def evaluate_gpt2_zeroshot(model, tokenizer, dataset):\n",
    "    predictions = []\n",
    "    references = dataset[\"queue\"]\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Use subset for quick testing if needed\n",
    "    # dataset = dataset.select(range(100))\n",
    "    \n",
    "    for item in tqdm(dataset, desc=\"Evaluating Agent 1\"):\n",
    "        prompt = generate_prompt_zeroshot(item[\"body\"])\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs, \n",
    "                max_new_tokens=10, \n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "                do_sample=False\n",
    "            )\n",
    "        \n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        # Extract answer\n",
    "        answer = generated_text[len(prompt):].strip().split('\\n')[0]\n",
    "        \n",
    "        # Simple mapping\n",
    "        pred_label = \"Unknown\"\n",
    "        for label in label_list:\n",
    "            if label.lower() in answer.lower():\n",
    "                pred_label = label\n",
    "                break\n",
    "        predictions.append(pred_label)\n",
    "        \n",
    "    end_time = time.time()\n",
    "    accuracy = accuracy_score(references, predictions)\n",
    "    return accuracy, end_time - start_time\n",
    "\n",
    "acc_agent1, time_agent1 = evaluate_gpt2_zeroshot(model_gpt2, tokenizer_gpt2, test_ds)\n",
    "print(f\"Agent 1 Accuracy: {acc_agent1:.4f}\")\n",
    "print(f\"Agent 1 Time: {time_agent1:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 2: GPT-2 Fine-tuning (LoRA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LoraConfig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# --- Agent 2: GPT-2 Fine-tuning (LoRA) ---\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# PEFT Config\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m peft_config \u001b[38;5;241m=\u001b[39m \u001b[43mLoraConfig\u001b[49m(\n\u001b[1;32m      5\u001b[0m     task_type\u001b[38;5;241m=\u001b[39mTaskType\u001b[38;5;241m.\u001b[39mCAUSAL_LM, \n\u001b[1;32m      6\u001b[0m     inference_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[1;32m      7\u001b[0m     r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, \n\u001b[1;32m      8\u001b[0m     lora_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, \n\u001b[1;32m      9\u001b[0m     lora_dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m model_gpt2_lora \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name_gpt2)\n\u001b[1;32m     13\u001b[0m model_gpt2_lora \u001b[38;5;241m=\u001b[39m get_peft_model(model_gpt2_lora, peft_config)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LoraConfig' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Agent 2: GPT-2 Fine-tuning (LoRA) ---\n",
    "\n",
    "# PEFT Config\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, \n",
    "    inference_mode=False, \n",
    "    r=8, \n",
    "    lora_alpha=32, \n",
    "    lora_dropout=0.1\n",
    ")\n",
    "\n",
    "model_gpt2_lora = AutoModelForCausalLM.from_pretrained(model_name_gpt2)\n",
    "model_gpt2_lora = get_peft_model(model_gpt2_lora, peft_config)\n",
    "model_gpt2_lora.print_trainable_parameters()\n",
    "model_gpt2_lora.to(device)\n",
    "\n",
    "# Prepare Data for Causal LM training\n",
    "def format_ds_agent2(example):\n",
    "    prompt = generate_prompt_zeroshot(example[\"body\"])\n",
    "    completion = f\" {example['queue']}\" + tokenizer_gpt2.eos_token\n",
    "    text = prompt + completion\n",
    "    return {\"text\": text}\n",
    "\n",
    "train_ds_lora = train_ds.map(format_ds_agent2)\n",
    "val_ds_lora = val_ds.map(format_ds_agent2)\n",
    "\n",
    "def tokenize_function_causal(examples):\n",
    "    return tokenizer_gpt2(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "tokenized_train_lora = train_ds_lora.map(tokenize_function_causal, batched=True)\n",
    "tokenized_val_lora = val_ds_lora.map(tokenize_function_causal, batched=True)\n",
    "\n",
    "# Training\n",
    "training_args_lora = TrainingArguments(\n",
    "    output_dir=\"./results_agent2\",\n",
    "    per_device_train_batch_size=4,\n",
    "    num_train_epochs=1, # Increase for better results\n",
    "    learning_rate=2e-4,\n",
    "    logging_steps=100,\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\", # or \"no\" if val set is small\n",
    "    use_cpu=not torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "trainer_lora = Trainer(\n",
    "    model=model_gpt2_lora,\n",
    "    args=training_args_lora,\n",
    "    train_dataset=tokenized_train_lora,\n",
    "    eval_dataset=tokenized_val_lora,\n",
    ")\n",
    "\n",
    "print(\"Training Agent 2...\")\n",
    "trainer_lora.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_gpt2_lora' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate Agent 2\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel_gpt2_lora\u001b[49m\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      3\u001b[0m acc_agent2, time_agent2 \u001b[38;5;241m=\u001b[39m evaluate_gpt2_zeroshot(model_gpt2_lora, tokenizer_gpt2, test_ds)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent 2 Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_agent2\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_gpt2_lora' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate Agent 2\n",
    "model_gpt2_lora.eval()\n",
    "acc_agent2, time_agent2 = evaluate_gpt2_zeroshot(model_gpt2_lora, tokenizer_gpt2, test_ds)\n",
    "print(f\"Agent 2 Accuracy: {acc_agent2:.4f}\")\n",
    "print(f\"Agent 2 Time: {time_agent2:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 3: DistilBERT Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AutoTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# --- Agent 3: DistilBERT Classifier ---\u001b[39;00m\n\u001b[1;32m      3\u001b[0m model_name_bert \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistilbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m tokenizer_bert \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name_bert)\n\u001b[1;32m      5\u001b[0m model_bert \u001b[38;5;241m=\u001b[39m DistilBertForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      6\u001b[0m     model_name_bert, \n\u001b[1;32m      7\u001b[0m     num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(label_list), \n\u001b[1;32m      8\u001b[0m     id2label\u001b[38;5;241m=\u001b[39mid2label, \n\u001b[1;32m      9\u001b[0m     label2id\u001b[38;5;241m=\u001b[39mlabel2id\n\u001b[1;32m     10\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtokenize_function_bert\u001b[39m(examples):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AutoTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Agent 3: DistilBERT Classifier ---\n",
    "\n",
    "model_name_bert = \"distilbert-base-uncased\"\n",
    "tokenizer_bert = AutoTokenizer.from_pretrained(model_name_bert)\n",
    "model_bert = DistilBertForSequenceClassification.from_pretrained(\n",
    "    model_name_bert, \n",
    "    num_labels=len(label_list), \n",
    "    id2label=id2label, \n",
    "    label2id=label2id\n",
    ").to(device)\n",
    "\n",
    "def tokenize_function_bert(examples):\n",
    "    return tokenizer_bert(examples[\"body\"], truncation=True, max_length=512)\n",
    "\n",
    "tokenized_train_bert = train_ds.map(tokenize_function_bert, batched=True)\n",
    "tokenized_val_bert = val_ds.map(tokenize_function_bert, batched=True)\n",
    "tokenized_test_bert = test_ds.map(tokenize_function_bert, batched=True)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer_bert)\n",
    "\n",
    "training_args_bert = TrainingArguments(\n",
    "    output_dir=\"./results_agent3\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    use_cpu=not torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "trainer_bert = Trainer(\n",
    "    model=model_bert,\n",
    "    args=training_args_bert,\n",
    "    train_dataset=tokenized_train_bert,\n",
    "    eval_dataset=tokenized_val_bert,\n",
    "    tokenizer=tokenizer_bert,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=lambda p: {\"accuracy\": accuracy_score(p.label_ids, np.argmax(p.predictions, axis=1))}\n",
    ")\n",
    "\n",
    "print(\"Training Agent 3...\")\n",
    "trainer_bert.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate Agent 3\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m start_time \u001b[38;5;241m=\u001b[39m \u001b[43mtime\u001b[49m\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      3\u001b[0m metrics \u001b[38;5;241m=\u001b[39m trainer_bert\u001b[38;5;241m.\u001b[39mevaluate(tokenized_test_bert)\n\u001b[1;32m      4\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate Agent 3\n",
    "start_time = time.time()\n",
    "metrics = trainer_bert.evaluate(tokenized_test_bert)\n",
    "end_time = time.time()\n",
    "\n",
    "acc_agent3 = metrics[\"eval_accuracy\"]\n",
    "time_agent3 = end_time - start_time\n",
    "\n",
    "print(f\"Agent 3 Accuracy: {acc_agent3:.4f}\")\n",
    "print(f\"Agent 3 Time: {time_agent3:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'acc_agent1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# --- Comparison ---\u001b[39;00m\n\u001b[1;32m      2\u001b[0m methods \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPT-2 Zero-Shot\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPT-2 LoRA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistilBERT\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m accuracies \u001b[38;5;241m=\u001b[39m [\u001b[43macc_agent1\u001b[49m, acc_agent2, acc_agent3]\n\u001b[1;32m      4\u001b[0m times \u001b[38;5;241m=\u001b[39m [time_agent1, time_agent2, time_agent3]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMethod\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<20\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<10\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime (s)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m<10\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'acc_agent1' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Comparison ---\n",
    "methods = ['GPT-2 Zero-Shot', 'GPT-2 LoRA', 'DistilBERT']\n",
    "accuracies = [acc_agent1, acc_agent2, acc_agent3]\n",
    "times = [time_agent1, time_agent2, time_agent3]\n",
    "\n",
    "print(f\"{'Method':<20} | {'Accuracy':<10} | {'Time (s)':<10}\")\n",
    "print(\"-\" * 44)\n",
    "for m, a, t in zip(methods, accuracies, times):\n",
    "    print(f\"{m:<20} | {a:<10.4f} | {t:<10.2f}\")\n",
    "\n",
    "# Plot\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Method')\n",
    "ax1.set_ylabel('Accuracy', color=color)\n",
    "ax1.bar(methods, accuracies, color=color, alpha=0.6)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  \n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('Time (s)', color=color)  \n",
    "ax2.plot(methods, times, color=color, marker='o')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()  \n",
    "plt.title(\"Method Comparison\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 26.0.1 is available.\n",
      "You should consider upgrading via the '/Users/ab/Desktop/NLP/NLP class 1/LLM_Project_2025/venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install transformers datasets torch accelerate peft scikit-learn tqdm matplotlib --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (898761564.py, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[9], line 20\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f\"Test size: {len(test_ds)}\")http://localhost:8888/tree\u001b[0m\n\u001b[0m                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "# from config import * # Not needed\n",
    "from datapreparation import load_and_prepare_data\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load Data\n",
    "train_ds, val_ds, test_ds, label_list, label2id, id2label = load_and_prepare_data()\n",
    "\n",
    "print(f\"Train size: {len(train_ds)}\")\n",
    "print(f\"Test size: {len(test_ds)}\")http://localhost:8888/tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
